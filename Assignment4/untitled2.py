# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nfnfCz5LA0hl_sKzO0cDoMbF21w_Yici
"""

!nvidia-smi -L || true
!nvidia-smi --query-gpu=name,memory.total,driver_version --format=csv || true

import os, time, torch, torch.nn as nn, torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import numpy as np, pandas as pd, matplotlib.pyplot as plt

OUT_DIR = '/content/assignment4_outputs'
os.makedirs(OUT_DIR, exist_ok=True)
print("Outputs will be saved to", OUT_DIR)

SEED = 42
torch.manual_seed(SEED)
np.random.seed(SEED)

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])
train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)
print(f"Train: {len(train_dataset)}, Test: {len(test_dataset)}")

class SmallMLP(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(nn.Flatten(), nn.Linear(28*28, 128), nn.ReLU(), nn.Linear(128, 10))
    def forward(self, x): return self.net(x)

class MediumMLP(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(nn.Flatten(),
                                 nn.Linear(28*28, 512), nn.ReLU(),
                                 nn.Linear(512, 256), nn.ReLU(),
                                 nn.Linear(256, 10))
    def forward(self, x): return self.net(x)

class LargeCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(1,32,3,padding=1), nn.ReLU(),
            nn.Conv2d(32,64,3,padding=1), nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(64,128,3,padding=1), nn.ReLU(),
            nn.MaxPool2d(2))
        self.fc = nn.Sequential(nn.Flatten(), nn.Linear(128*7*7,256), nn.ReLU(), nn.Linear(256,10))
    def forward(self,x): return self.fc(self.conv(x))

print("Models defined ✅")

def train_one_epoch(model, device, dataloader, optimizer, criterion, scaler=None):
    model.train(); t0 = time.time(); total, correct, loss_sum = 0, 0, 0
    for X,y in dataloader:
        X,y = X.to(device), y.to(device)
        optimizer.zero_grad()
        if scaler:
            with torch.cuda.amp.autocast():
                out = model(X); loss = criterion(out, y)
            scaler.scale(loss).backward(); scaler.step(optimizer); scaler.update()
        else:
            out = model(X); loss = criterion(out, y); loss.backward(); optimizer.step()
        loss_sum += loss.item() * X.size(0)
        correct += (out.argmax(1)==y).sum().item(); total += X.size(0)
    return loss_sum/total, correct/total, time.time()-t0

def evaluate(model, device, dataloader, criterion):
    model.eval(); loss_sum, correct, total = 0, 0, 0
    with torch.no_grad():
        for X,y in dataloader:
            X,y = X.to(device), y.to(device)
            out = model(X)
            loss_sum += criterion(out,y).item() * X.size(0)
            correct += (out.argmax(1)==y).sum().item(); total += X.size(0)
    return loss_sum/total, correct/total

def measure_train(device, model_ctor, train_loader, test_loader, epochs=1, lr=1e-3, use_amp=False):
    model = model_ctor().to(device)
    opt = torch.optim.Adam(model.parameters(), lr=lr)
    crit = nn.CrossEntropyLoss()
    scaler = torch.cuda.amp.GradScaler() if (use_amp and device.type=='cuda') else None
    times=[]
    for ep in range(epochs):
        tr_loss, tr_acc, t = train_one_epoch(model, device, train_loader, opt, crit, scaler)
        val_loss, val_acc = evaluate(model, device, test_loader, crit)
        print(f"Epoch {ep+1}/{epochs} | time {t:.2f}s | acc {val_acc:.4f}")
        times.append(t)
    return {'epoch_times': times, 'val_acc': val_acc, 'params': sum(p.numel() for p in model.parameters())}

def run_cpu_vs_gpu():
    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)
    test_loader  = DataLoader(test_dataset, batch_size=1024, shuffle=False, num_workers=2, pin_memory=True)
    results={}
    for device in [torch.device('cpu'), torch.device('cuda' if torch.cuda.is_available() else 'cpu')]:
        print(f"\n=== Running on {device} ===")
        torch.manual_seed(SEED)
        results[str(device)] = measure_train(device, LargeCNN, train_loader, test_loader, epochs=1)
    return results

def run_batch_sizes():
    rows=[]
    for bs in [16,64,256,1024]:
        train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True, num_workers=2, pin_memory=True)
        test_loader  = DataLoader(test_dataset, batch_size=1024, shuffle=False, num_workers=2, pin_memory=True)
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        res = measure_train(device, LargeCNN, train_loader, test_loader, epochs=1)
        rows.append({'batch_size':bs,'time':res['epoch_times'][0],'acc':res['val_acc']})
    df=pd.DataFrame(rows); df.to_csv(f"{OUT_DIR}/batch_size.csv",index=False); return df

def run_models():
    models=[('Small',SmallMLP),('Medium',MediumMLP),('Large',LargeCNN)]
    rows=[]
    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    for name,ctor in models:
        print(f"\n=== {name} ===")
        train_loader=DataLoader(train_dataset,batch_size=128,shuffle=True,num_workers=2,pin_memory=True)
        test_loader=DataLoader(test_dataset,batch_size=1024,shuffle=False,num_workers=2,pin_memory=True)
        res=measure_train(device,ctor,train_loader,test_loader,epochs=1)
        rows.append({'model':name,'time':res['epoch_times'][0],'acc':res['val_acc']})
    df=pd.DataFrame(rows); df.to_csv(f"{OUT_DIR}/models.csv",index=False); return df

cpu_gpu=run_cpu_vs_gpu(); print(cpu_gpu)
df_bs=run_batch_sizes(); print(df_bs)
df_md=run_models(); print(df_md)

plt.plot(df_bs['batch_size'], df_bs['time'], marker='o')
plt.title("Batch Size vs Time"); plt.xlabel("Batch Size"); plt.ylabel("Time (s)"); plt.grid(); plt.show()
plt.bar(df_md['model'], df_md['time']); plt.title("Model Complexity vs Time"); plt.ylabel("Time (s)"); plt.show()

print("\n✅ Done — results saved in", OUT_DIR)
